---
title: "Product Segmentation"
author: "Seung Hyun Sung"
date: "2/4/2022"
output: 
    html_document:
        theme: flatly
        toc: true
        toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    message = FALSE,
    warning = FALSE)
```

```{r libraries}
# libraries
library(DT)
library(knitr)
library(lubridate)
library(timetk)
library(tidytext)
library(plotly)
library(ggwordcloud)
library(ggiraphExtra)
library(fs)
library(readr)
library(tidyverse)
library(tidymodels)
library(tidyquant)
library(umap)
# Python integration 
library(reticulate)
```

## Setup R' spython interface (conda py3.8 Environment)

conda create -n py3.8 python=3.8 scikit-learn pandas numpy matplotlib
 This code does the following:
   - Creates a new Python environment called “py3.8”
   - Installs python version 3.8
   - Installs the latest versions of scikit-learn, pandas, numpy, and matplotlib.

Replace this with your conda environment containing sklearn, pandas, & numpy

```{r}
use_condaenv("py3.8", required = TRUE)
```


# 1. Data 

```{r}
retail_order_tbl <-  read_rds("00_Data/data_wranggled/trans_data/retail_order_tbl.rds")

products_manual_tbl <-  read_rds("00_Data/data_wranggled/product_data/products_manual_tbl.rds")
```


# 2. Product (Unsupervised) Clustering 

__Hypothesis:__
- Similar Products are Purchased by Similar Seasonal Trend (Month)
- 


# 3. Products Feature Engineering 

__Problems:__
- Products are highly unique and has no categories 
- Need categories to learn which customers are similar

__Solution:__
- Product Purchase Frequency 
- Price Feature Engineering will help group products by price categories 
-  Text Feature Engineering is essential to compare description fields



## Product Rank by purchase frequency 
- Possible alternatives: 
    - Rank product by customer retention (monthly)
    - Rank product by seasonal robustness 
    
__Findings:__



## 3.1 Retention Time Feature Engineering 
-- Seasonality Trend Preserved 

### 3.1.1 Rank Product by Purchase Frequency 

```{r}

rank_product_frequency_tbl <- retail_order_tbl %>% 
    count(description, stock_code) %>% 
    arrange(desc(n)) %>% 
    mutate(
        pct = n/ sum(n),
        cumulative_pct = cumsum(pct),
        priority = ifelse(cumulative_pct <= 0.5, "yes", "no")
    ) %>% 
    rowid_to_column(var = "rank") %>% 
    mutate(label_text = str_glue("Rank: {rank}
                                 Product: {description}
                                 Stock Code: {stock_code}
                                 Count: {n}
                                 Pct: {scales::percent(pct)}
                                 cumulative Pct: {scales::percent(cumulative_pct)}"))


g <- rank_product_frequency_tbl %>% 
    slice(1:2000) %>% 
    ggplot(aes(rank, n, text = label_text)) +
    geom_point(aes(colour = priority, size = n), alpha = 0.3) +
    scale_colour_tq() +
    theme_tq() +
    theme(legend.direction = "vertical",
          legend.position = "right") +
    labs(title = "Item Frequency",
         subtitle = "Top Items Account for Majority of Purchases")

g %>% ggplotly(tooltip = "text")
```

### 3.1.2 Filter Product by Rank 

```{r}
filter_freq_item_list <- rank_item_frequency_tbl %>% filter(priority == "yes") %>% pull(stock_code)

product_weekly_users_tbl <- retail_order_tbl %>% 
    select(invoice_id, invoice_date, stock_code) %>% 
    filter(stock_code %in% filter_freq_item_list) %>% 
    mutate(invoice_period = floor_date(invoice_date, "week")) %>% 
    group_by(invoice_period, stock_code) %>% 
    summarise(
        .groups = "drop",
        frequency = n()
    ) 

product_retention_tbl <- product_weekly_users_tbl %>% 
    select(stock_code, invoice_period, frequency) %>% 
    group_by(stock_code) %>% 
    mutate(n = sum(frequency),
           retention    = frequency/n) %>% 
    ungroup() %>% 
    select(-frequency)


product_retention_time_feature_tbl <- product_retention_tbl %>% 
    pivot_wider(
        names_from = invoice_period,
        values_from = retention,
        values_fill = list(retention = 0),
        values_fn = list(retention = sum)
    ) 

product_retention_time_feature_tbl
```


### 3.2 Price Feature Engineering 
- Highly Skewed (damaging for distance based clustering) 

```{r}
product_price_range_tbl <- retail_order_tbl %>% 
  group_by(stock_code) %>% 
  summarise(
    .groups     = "drop",
    n_prices    = n(),
    mean_price  = mean(unit_price),
    min_price   = min(unit_price),
    p25_price   = quantile(unit_price)[2],
    p50_price   = quantile(unit_price)[3],
    p75_price   = quantile(unit_price)[4],
    max_price   = max(unit_price),
    range_price = ((max_price - min_price)/ mean_price) %>% round(4)
  ) 

```


```{r}
products_manual_tbl %>% 
    ggplot(aes(median_unit_price)) +
    geom_histogram()

products_manual_tbl %>% 
    ggplot(aes(log(median_unit_price +1))) +
    geom_histogram()

```


### 3.3 Text Feature Engineering
- Use 'tidytext' to unnest tokens 
- Stems the tokens using 'hunspell' to return only the root of the word 

```{r}
product_disctionary <- function(data){
    out_tbl <- data %>% 
    select(stock_code, mode_description) %>% 
    unnest_tokens(terms, mode_description, token = "words") %>% 
    filter(!(nchar(terms) == 1)) %>% 
    mutate(terms = hunspell::hunspell_stem(terms)) %>% 
    unnest(terms) %>% 
    mutate(n = 1)
    return(out_tbl)
}
products_disctionary_tbl <- products_manual_tbl %>%
    product_disctionary()

```


### 3.3.1 Term Frequency

- count Frequency 
- Remove Stop words (e.g. "of" has no meaning)
- Remove colour terms(e.g. "pink" has no meanings)
- Remove terms with numbers (e.g. "130.5cm" has no meaning)

```{r}
terms_frequency_tbl <- products_disctionary_tbl %>% 
    # Remove unnecessary terms 
    anti_join(stop_words, by = c("terms" = "word")) %>% 
    # Remove colour terms 
    filter(!terms %in% colours()) %>% 
    # Remove terms with numbers 
    filter(!terms %>% str_detect(pattern = "[0-9]")) %>% 
    # summarise -0> abstract frequency 
    group_by(terms) %>% 
    summarise(
        n = sum(n)
    ) %>% 
    arrange(desc(n))

terms_frequency_tbl
```


### 3.3.2 Term Frequency Visualisation

```{r}
rank_term_frequency_tbl <- terms_frequency_tbl %>% 
    arrange(desc(n)) %>% 
    mutate(
        pct = n/ sum(n),
        cumulative_pct = cumsum(pct),
        priority = ifelse(cumulative_pct <= 0.5, "yes", "no")
    ) %>% 
    rowid_to_column(var = "rank") %>% 
    mutate(label_text = str_glue("Rank: {rank}
                                 Stock Code: {terms}
                                 Count: {n}
                                 Pct: {scales::percent(pct)}
                                 cumulative Pct: {scales::percent(cumulative_pct)}"))


g <- rank_term_frequency_tbl %>% 
    slice(1:1000) %>% 
    ggplot(aes(rank, n, text = label_text)) +
    geom_point(aes(colour = priority, size = n), alpha = 0.3) +
    scale_colour_tq() +
    theme_tq() +
    theme(legend.direction = "vertical",
          legend.position = "right") +
    labs(title = "Term Frequency")

g %>% ggplotly(tooltip = "text")

```



```{r}
terms_frequency_tbl %>% 
    slice(1:100) %>% 
    mutate(terms = as_factor(terms) %>% fct_rev()) %>% 
    ggplot() + 
    geom_text_wordcloud_area(aes(label = terms, size = n, colour = n)) +
    scale_size_area(max_size = 14) +
    scale_colour_viridis_c(direction = -1) +
    theme(plot.background = element_rect(fill = "black"),
          panel.background = element_rect(fill = "black"))
```


### 3.3.3 Fiter Term Frequency 

```{r}
top_100_terms <- terms_frequency_tbl %>% slice(1:100) %>% pull(terms)

product_term_feature_tbl <- products_disctionary_tbl %>% 
    filter(terms %in% top_100_terms) %>% 
    pivot_wider(
        names_from = terms,
        values_from = n,
        values_fill = list(n = 0),
        values_fn = list(n = sum)
    )
```


#  4. Modelling 

## 4.1 Join Products Categorization Data 
-- 

```{r}
products_term_joined_tbl <- products_manual_tbl %>% 
    left_join(product_term_feature_tbl) %>% 
    drop_na()

products_retention_joined_tbl <- products_manual_tbl %>% 
    select(-n) %>% 
    left_join(product_retention_time_feature_tbl, by = "stock_code") %>% 
    drop_na()
```


##  4.2 Prepare Recipe for Modelling 

```{r}
recipe_spec_product_term <- recipe(~., data = products_term_joined_tbl) %>% 
        # Preprocessing steps as follows: 
    # Remove unnecessary features for clustering 
    step_rm(stock_code, n, mode_description) %>% 
    # Apply log transformation on the median_unit_price + 1 (offset) 
    step_log(median_unit_price, offset = 1) %>% 
    # scale to the range of [0,1]
    step_range(median_unit_price) %>% 
    prep()

recipe_spec_product_retention <- recipe(~., data = products_retention_joined_tbl) %>% 
    step_rm(stock_code, n, mode_description) %>% 
    step_log(median_unit_price, offset = 1) %>% 
    step_range(median_unit_price) %>% 
    prep()

```

## 4.3 
```{r}
product_retention_clusters_tbl <- read_rds("00_Data/data_wranggled/cluster_data/product_retention_clusters_tbl.rds")

product_term_clusters_tbl <- read_rds("00_Data/data_wranggled/cluster_data/product_term_clusters_tbl.rds")
```



# Customer Features 

## Join Product Categories 

```{r}

transaction_product_clusters_tbl <- retail_order_tbl %>% 
  left_join(
    product_term_clusters_tbl %>% 
      rename(term_cluster = cluster) %>% 
      group_by(stock_code) %>% 
      slice(1) %>% 
      ungroup()
    ) %>% 
    left_join(
    product_retention_clusters_tbl %>% 
      rename(ret_cluster = cluster) %>% 
      group_by(stock_code) %>% 
      slice(1) %>% 
      ungroup(),
    by = "stock_code"
    ) %>% 
  select(
    customer_id, invoice_id, invoice_date, stock_code, description, term_cluster, ret_cluster, unit_price, quantity, stock_price
  )
```


```{r}
customer_spend_habits_tbl <- transaction_product_clusters_tbl %>%
    
    # Get spend by Invoice (Purchase)
    group_by(customer_id, invoice_id) %>%
    summarize(order_value = sum(stock_price)) %>%
    ungroup() %>%
    
    # Aggregate by Customer ID
    group_by(customer_id) %>%
    summarize(
        count  = n(),
        min    = min(order_value),
        mean   = mean(order_value),
        max    = max(order_value),
        sum    = sum(order_value)
    ) %>%
    ungroup()

customer_spend_habits_tbl
```



## Characterize Product Categories

```{r}
customer_product_habits_1_tbl <- transaction_product_clusters_tbl %>%
    select(customer_id, stock_price, term_cluster) %>%
    group_by(customer_id, term_cluster) %>%
    summarize(stock_price = sum(stock_price)) %>%
    mutate(prop = stock_price / sum(stock_price)) %>%
    ungroup() %>%
    select(-stock_price) %>%
    pivot_wider(names_from   = term_cluster, 
                values_from  = prop, 
                values_fill  = list(prop = 0), 
                names_prefix = "term_") 

customer_product_habits_1_tbl
```


```{r}
customer_product_habits_2_tbl <- transaction_product_clusters_tbl %>%
    select(customer_id, stock_price, ret_cluster) %>%
    group_by(customer_id, ret_cluster) %>%
    summarize(stock_price = sum(stock_price)) %>%
    mutate(prop = stock_price / sum(stock_price)) %>%
    ungroup() %>%
    select(-stock_price) %>%
    pivot_wider(names_from   = ret_cluster, 
                values_from  = prop, 
                values_fill  = list(prop = 0), 
                names_prefix = "ret_") 

customer_product_habits_2_tbl
```


## Characterize Recency in Purchases

```{r}
max_date <- max(transaction_product_clusters_tbl$invoice_date)

customer_recency_habits_tbl <- transaction_product_clusters_tbl %>%
    count(customer_id, invoice_date) %>%
    group_by(customer_id) %>%
    summarise(
        first_pur = -1 * (min(invoice_date) - max_date)  / ddays(1),
        last_pur  = -1 * (max(invoice_date) - max_date)  / ddays(1)
    )

customer_recency_habits_tbl
```


## Join Customer Habits

```{r}
customer_habits_joined_tbl <- customer_spend_habits_tbl %>%
    left_join(customer_product_habits_1_tbl) %>%
    left_join(customer_product_habits_2_tbl) 

customer_habits_joined_tbl
```



```{r}

kmeans_mapper <- function(center = 1) {
    recipe_spec_product_term %>% juice() %>%
        kmeans(centers = center, nstart = 20)
}

centers_tbl <- tibble(centers = 1:15)

k_means_mapped_tbl <- centers_tbl %>% 
    mutate(k_means = centers %>% map(kmeans_mapper),
           glance = k_means %>% map(broom::glance))

k_means_mapped_tbl %>% 
    unnest(glance) %>% 
    ggplot(aes(x = centers, y = tot.withinss), colour = "#2c3e50") +
    geom_point(colour = "#2c3e50", size = 3) +
    geom_line(colour = "#2c3e50", size = 1) +
    ggrepel::geom_label_repel(aes(label = centers), colour = "#2c3e50", size = 4) +
    theme_tq()
```


```{r}
k_means_8_obj <- k_means_mapped_tbl %>% 
    filter(centers == 8) %>% 
    pull(k_means) %>%  pluck(1)

TEST <- k_means_8_obj %>% 
    broom::augment(products_joined_tbl) %>% 
    select(stock_code, .cluster) %>% 
    left_join(products_manual_tbl, by = "stock_code")

TEST %>% 
    filter(.cluster == 5) %>% 
    pull(mode_description)
```



```{r}
product_clusters_tbl <- read_rds("00_Data/data_wranggled/product_data/product_clusters_tbl.rds")
```

```{r}
g <- product_clusters_tbl %>% 
    mutate(mode_description = str_remove_all(mode_description, "[^A-Za-z0-9 -]")) %>% 
    mutate(tooltip = str_glue("Desc: {mode_description}
                              Price: {median_unit_price}")) %>% 
    ggplot(aes(V1, V2, colour = cluster)) +
    geom_point(aes(text = tooltip), alpha = 0.7) +
    scale_colour_tq() +
    theme_tq()

ggplotly(g, tooltip = "text")
```


```{r}
term_freq_by_cluster_tbl <- product_clusters_tbl %>% 
    unnest_tokens(terms, mode_description, token = "words") %>% 
    mutate(terms = hunspell::hunspell_stem(terms)) %>% 
    unnest(terms) %>% 
    
    # Remove stop words
    anti_join(stop_words, by = c("terms" = "word")) %>% 
    filter(!terms %in% colours()) %>% 
    filter(!terms %>% str_detect(pattern = "[0-9]")) %>% 
    
    mutate(n = 1) %>% 
    group_by(cluster, terms) %>% 
    summarise(n = sum(n)) %>% 
    arrange(desc(n), .by_group = TRUE) %>% 
    slice(1:50)
```


```{r}
g <- term_freq_by_cluster_tbl %>% 
    slice(1:10) %>% 
    ungroup() %>% 
    arrange(desc(n)) %>% 
    mutate(terms = as_factor(terms) %>% fct_rev()) %>% 
    ggplot(aes(n, terms, colour = cluster)) +
    geom_point() +
    expand_limits(x = 0) +
    facet_wrap(~cluster, ncol = 2, scales = "free_y") +
    scale_colour_tq() +
    labs(y = "")


g %>% ggplotly()
```




